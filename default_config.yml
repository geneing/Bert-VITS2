# Global Configuration
# For situations where multiple configuration files are needed at the same time, such as running two training sets on two GPUs simultaneously: specify the configuration file through environment variables, default is ./config.yml if not specified

# Provide a common path configuration to store data uniformly, avoiding messy data storage
# Each dataset and its corresponding model are stored under a unified path, and all subsequent path configurations are relative to datasetPath
# If not filled or left blank, the path is relative to the project root directory
dataset_path: "Data/"

# Model mirror source, default is huggingface, specify openi_token to use openi mirror source
mirror: ""
openi_token: ""  # openi token

# resample audio resampling configuration
# Note, a space is needed after ":"
resample:
  # Target resampling rate
  sampling_rate: 44100
  # Input path for audio files, resampling will be applied to all .wav audio files under this path
  # Please fill in the relative path to datasetPath
  in_dir: "audios/raw" # Relative path to the root directory is /datasetPath/in_dir
  # Output path for resampled audio files
  out_dir: "audios/wavs"

# preprocess_text dataset preprocessing related configuration
# Note, a space is needed after ":"
preprocess_text:
  # Path to the original text file, the text format should be {wav_path}|{speaker_name}|{language}|{text}.
  transcription_path: "filelists/your_dataset_text.list"
  # Path to the cleaned text file, can be left blank. If left blank, it will be generated in the original text directory
  cleaned_path: ""
  # Training set path
  train_path: "filelists/train.list"
  # Validation set path
  val_path: "filelists/val.list"
  # Configuration file path
  config_path: "config.json"
  # Number of validation set entries per language
  val_per_lang: 4
  # Maximum number of validation set entries, excess entries will be truncated and placed in the training set
  max_val_total: 12
  # Whether to perform data cleaning
  clean: true

# bert_gen related configuration
# Note, a space is needed after ":"
bert_gen:
  # Path to the training dataset configuration file
  config_path: "config.json"
  # Number of parallel processes
  num_processes: 4
  # Device to use: options are "cuda" for GPU inference, "cpu" for CPU inference
  # This option also determines the default device for get_bert_feature
  device: "cuda"
  # Use multiple devices for inference
  use_multi_device: false

# emo_gen related configuration
# Note, a space is needed after ":"
emo_gen:
  # Path to the training dataset configuration file
  config_path: "config.json"
  # Number of parallel processes
  num_processes: 4
  # Device to use: options are "cuda" for GPU inference, "cpu" for CPU inference
  device: "cuda"
  # Use multiple devices for inference
  use_multi_device: false

# train training configuration
# Note, a space is needed after ":"
train_ms:
  env:
    MASTER_ADDR: "localhost"
    MASTER_PORT: 10086
    WORLD_SIZE: 1
    LOCAL_RANK: 0
    RANK: 0
    # You can fill in any environment variable name
    # THE_ENV_VAR_YOU_NEED_TO_USE: "1234567"
  # Base model settings
  base:
    use_base_model: false
    repo_id: "Stardust_minus/Bert-VITS2"
    model_image: "Bert-VITS2_2.3 base model" # Model name on the openi webpage
  # Directory for storing training models: different from the old version, the dataset was previously stored under logs/model_name, now it is uniformly stored under Data/your_dataset/models
  model: "models"
  # Configuration file path
  config_path: "configs/config.json"
  # Number of workers used for training, not recommended to exceed the number of CPU cores
  num_workers: 16
  # Disabling this option can save nearly 70% of disk space, but may result in slower actual training speed and higher CPU usage.
  spec_cache: False
  # Number of saved checkpoints, weights exceeding this number will be deleted to save space.
  keep_ckpts: 8

# webui webui configuration
# Note, a space is needed after ":"
webui:
  # Inference device
  device: "cuda"
  # Model path
  model: "models/G_8000.pth"
  # Configuration file path
  config_path: "configs/config.json"
  # Port number
  port: 7860
  # Whether to deploy publicly, open to the external network
  share: false
  # Whether to enable debug mode
  debug: false
  # Language identification library, options are langid, fastlid
  language_identification_library: "langid"

# server-fastapi configuration
# Note, a space is needed after ":"
# Note, all configurations under this configuration are relative to the root directory
server:
  # Port number
  port: 5000
  # Default device for models: this configuration is not currently implemented.
  device: "cuda"
  # Configuration for all models to be loaded, multiple models can be filled in, or no models can be filled in, and models can be manually loaded after the webpage is successfully loaded
  # Configuration format for not loading models: delete the two default model configurations, assign an empty list to models, i.e., models: [ ]. Refer to the speakers of model 2, i.e., models: [ ]
  # Note, all models must correctly configure the paths of model and config, empty paths will cause loading errors.
  # Models can also be left blank, and models can be manually filled in after the webpage is successfully loaded.
  models:
    - # Path to the model
      model: ""
      # Path to the model's config.json
      config: ""
      # Device to use for the model, if filled in, it will override the default configuration
      device: "cuda"
      # Default language for the model
      language: "ZH"
      # Default parameters for model characters
      # Not all characters need to be filled in, defaults will be used for those not filled in
      # Temporarily not required, currently not implemented to distinguish configuration by character
      speakers:
        - speaker: "Kobe"
          sdp_ratio: 0.2
          noise_scale: 0.6
          noise_scale_w: 0.8
          length_scale: 1
        - speaker: "Gojo Satoru"
          sdp_ratio: 0.3
          noise_scale: 0.7
          noise_scale_w: 0.8
          length_scale: 0.5
        - speaker: "Shinzo Abe"
          sdp_ratio: 0.2
          noise_scale: 0.6
          noise_scale_w: 0.8
          length_scale: 1.2
    - # Path to the model
      model: ""
      # Path to the model's config.json
      config: ""
      # Device to use for the model, if filled in, it will override the default configuration
      device: "cpu"
      # Default language for the model
      language: "JP"
      # Default parameters for model characters
      # Not all characters need to be filled in, defaults will be used for those not filled in
      speakers: [ ] # Can also be left blank

# Baidu Translate Open Platform API configuration
# API access documentation https://api.fanyi.baidu.com/doc/21
# Please do not publicly share your app id and key on websites like GitHub
translate:
  # Your APPID
  "app_key": ""
  # Your secret key
  "secret_key": ""
